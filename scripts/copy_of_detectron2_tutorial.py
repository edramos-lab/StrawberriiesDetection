# -*- coding: utf-8 -*-
"""Copy of Detectron2 Tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_CEU-MUXG4otuZGz9PP_zxklYKwrN6lC

# Detectron2 Beginner's Tutorial

<img src="https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png" width="500">

Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:
* Run inference on images or videos, with an existing detectron2 model
* Train a detectron2 model on a new dataset

You can make a copy of this tutorial by "File -> Open in playground mode" and make changes there. __DO NOT__ request access to this tutorial.

# Install detectron2
"""

!python -m pip install pyyaml==5.1
import sys, os, distutils.core
# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).
# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions
!git clone 'https://github.com/facebookresearch/detectron2'
dist = distutils.core.run_setup("./detectron2/setup.py")
!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}
sys.path.insert(0, os.path.abspath('./detectron2'))

# Properly install detectron2. (Please do not install twice in both ways)
# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

import torch, detectron2
!nvcc --version
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
print("detectron2:", detectron2.__version__)

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

"""# Run a pre-trained detectron2 model

We first download an image from the COCO dataset:
"""

!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg
im = cv2.imread("./input.jpg")
cv2_imshow(im)

"""Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."""

cfg = get_cfg()
# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
predictor = DefaultPredictor(cfg)
outputs = predictor(im)

# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification
print(outputs["instances"].pred_classes)
print(outputs["instances"].pred_boxes)

# We can use `Visualizer` to draw the predictions on the image.
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(out.get_image()[:, :, ::-1])

"""# Train on a custom dataset

In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.

We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)
which only has one class: balloon.
We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.

Note that COCO dataset does not have the "balloon" category. We'll be able to recognize this new class in a few minutes.

## Prepare the dataset
"""

# download, decompress the data
#!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip
#!unzip balloon_dataset.zip > /dev/null

!pip install roboflow

'''from roboflow import Roboflow
rf = Roboflow(api_key="FXnaEOpZe9U9LCoSUuMo")
project = rf.workspace("test-vwrlb").project("strawberrydisease-koflr")
version = project.version(1)
dataset = version.download("coco-segmentation")'''




from roboflow import Roboflow
rf = Roboflow(api_key="FXnaEOpZe9U9LCoSUuMo")
project = rf.workspace("test-vwrlb").project("strawberry-diseases-ze4b7")
version = project.version(1)
dataset = version.download("coco")

"""Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).
Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.

"""

import torch
import detectron2
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.data.datasets import register_coco_instances
import os

# prompt: rename file "/content/StrawberryDisease-1/train/_annotations.coco.json" to /content/StrawberryDisease-1/train/train.json and move it into a new folder within /content/StrawberryDisease-1/annotations using cmd commands

!mkdir /content/Strawberry-Diseases-1/annotations
!mv /content/Strawberry-Diseases-1/train/_annotations.coco.json /content/Strawberry-Diseases-1/annotations/train.json
!mv /content/Strawberry-Diseases-1/valid /content/Strawberry-Diseases-1/val
!mv /content/Strawberry-Diseases-1/val/_annotations.coco.json /content/Strawberry-Diseases-1/annotations/val.json
!mv /content/Strawberry-Diseases-1/test/_annotations.coco.json /content/Strawberry-Diseases-1/annotations/test.json

# Set dataset paths
data_dir = "/content/Strawberry-Diseases-1"
train_json = os.path.join(data_dir, "annotations", "train.json")
val_json = os.path.join(data_dir, "annotations", "test.json")
test_json = os.path.join(data_dir, "annotations", "val.json")
train_images = os.path.join(data_dir, "train")
val_images = os.path.join(data_dir, "test")
test_images = os.path.join(data_dir, "val")

# Register dataset in COCO
from detectron2.data.datasets import register_coco_instances
register_coco_instances("/content/Strawberry-Diseases-1/train", {}, train_json, train_images)
register_coco_instances("/content/Strawberry-Diseases-1/test", {}, val_json, val_images)
register_coco_instances("/content/Strawberry-Diseases-1/val", {}, test_json, test_images)

"""To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:


"""

from detectron2.data import MetadataCatalog, DatasetCatalog

dataset_dicts =  DatasetCatalog.get("/content/Strawberry-Diseases-1/train")

for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1],scale=0.5)
    out = visualizer.draw_dataset_dict(d)
    cv2_imshow(out.get_image()[:, :, ::-1])

"""## Train!

Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.

"""

!pip install wandb

!wandb login

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("/content/Strawberry-Diseases-1/train",)
cfg.DATASETS.TEST = ("/content/Strawberry-Diseases-1/test",) #set test to val
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
cfg.SOLVER.STEPS = []        # do not decay learning rate
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # only has one class of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.

cfg.SOLVER.IMS_PER_BATCH = 32  # This is the real "batch size" commonly known to deep learning people
cfg.SOLVER.BASE_LR =0.0001  # pick a good LR
cfg.SOLVER.MAX_ITER = 1000
cfg.TEST.EVAL_PERIOD = 200  # Validate every 200 iterations

import wandb
from detectron2.engine import DefaultTrainer, HookBase
from detectron2.evaluation import inference_on_dataset, COCOEvaluator
from detectron2.data import build_detection_test_loader

# Initialize WandB
wandb.init(project="detectron2-Strawberry-Diseases")

class WandbLoggerHook(HookBase):
    def __init__(self, trainer):
        self.trainer = trainer

    def after_step(self):
        if self.trainer.iter % 100 == 0:  # Log every 100 iterations
            metrics = {
                "train/loss": self.trainer.storage.latest()["total_loss"],
                "train/lr": self.trainer.storage.latest()["lr"],
                "train/iteration": self.trainer.iter
            }
            wandb.log(metrics)

class ValidationHook(HookBase):
    def __init__(self, trainer, eval_period):
        self.trainer = trainer
        self.eval_period = eval_period

    def after_step(self):
        if self.trainer.iter % self.eval_period == 0 and self.trainer.iter > 0:
            evaluator = COCOEvaluator("/content/Strawberry-Diseases-1/test", self.trainer.cfg, False, output_dir=self.trainer.cfg.OUTPUT_DIR)
            val_loader = build_detection_test_loader(self.trainer.cfg, "/content/Strawberry-Diseases-1/test")
            results = inference_on_dataset(self.trainer.model, val_loader, evaluator)

            # Log validation metrics in WandB
            #wandb.log({"validation/AP": results["bbox"]["AP"], "iteration": self.trainer.iter})
            # Log all validation metrics in WandB
            wandb.log({f"validation/{key}": value for key, value in results.items()}, step=self.trainer.iter)

class CustomTrainer(DefaultTrainer):
    def __init__(self, cfg):
        super().__init__(cfg)
        self.register_hooks([WandbLoggerHook(self), ValidationHook(self, cfg.TEST.EVAL_PERIOD)])

cfg.TEST.EVAL_PERIOD = 100  # Validate every 500 iterations
trainer = CustomTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()
wandb.finish()

from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.evaluation import inference_on_dataset
from detectron2.utils.events import EventWriter, EventStorage
import os
from datetime import datetime





cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("/content/Strawberry-Diseases-1/train",)
cfg.DATASETS.TEST = ("/content/Strawberry-Diseases-1/test",) #set test to val
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
cfg.SOLVER.STEPS = []        # do not decay learning rate
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 2   # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.

cfg.SOLVER.IMS_PER_BATCH = 32  # This is the real "batch size" commonly known to deep learning people
cfg.SOLVER.BASE_LR =0.001  # pick a good LR
cfg.SOLVER.MAX_ITER = 1000
cfg.TEST.EVAL_PERIOD = 300  # Validate every 1000 iterations





bss=[2,4]
lrr=[0.0001,0.00001]
for bs in bss:
  for lr in lrr:
    cfg.SOLVER.IMS_PER_BATCH = bs  # This is the real "batch size" commonly known to deep learning people
    cfg.SOLVER.BASE_LR =lr  # pick a good LR
    run_name = f"lr_{cfg.SOLVER.BASE_LR}_batch_{cfg.SOLVER.IMS_PER_BATCH}"
    cfg.OUTPUT_DIR = f"./output/{run_name}"
    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
    trainer = DefaultTrainer(cfg)
    trainer.resume_or_load(resume=False)
    trainer.train()
      # Pass the model as the argument to the test function
    # Set up the evaluator
    '''evaluator = COCOEvaluator("/content/Strawberry-Diseases-1/test",output_dir=cfg.OUTPUT_DIR)#cfg,False, output_dir=None)#output_dir=cfg.OUTPUT_DIR)
    val_loader = build_detection_test_loader(cfg, "/content/Strawberry-Diseases-1/test")
    # Use inference_on_dataset instead of trainer.test
    results=inference_on_dataset(trainer.model, val_loader, evaluator)
            # **Manually append test results to `metrics.json`**

    '''# **Ensure TensorBoard reads evaluation results**
    with EventStorage(start_iter=trainer.iter) as storage:
        for metric, value in results.items():
            if isinstance(value, dict):  # Handle nested metrics (e.g., bbox, segm)
                for sub_metric, sub_value in value.items():
                    if isinstance(sub_value, (float, int)):  # Ensure it's a scalar
                        if np.isnan(sub_value):  # Replace NaN with 0.0
                            sub_value = 0.0
                        storage.put_scalar(f"{metric}/{sub_metric}", sub_value)
            elif isinstance(value, (float, int)):  # Log direct scalar values
                if np.isnan(value):
                    value = 0.0
                storage.put_scalar(f"{metric}", value)'''

# Commented out IPython magic to ensure Python compatibility.

# %reload_ext tensorboard
# %tensorboard --logdir output

"""## Inference & evaluation using the trained model
Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:


"""

# Inference should use the config with parameters that are used in training
# cfg now already contains everything we've set previously. We changed it a little bit for inference:
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "/content/output/lr_1e-05_batch_2/model_final.pth")  # path to the model we just trained
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold
predictor = DefaultPredictor(cfg)

"""Then, we randomly select several samples to visualize the prediction results."""

from detectron2.utils.visualizer import ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog

dataset_dicts =  DatasetCatalog.get("/content/Strawberry-Diseases-1/test")
print(dataset_dicts)
#dataset_dicts = get_balloon_dicts("balloon/val")
for d in random.sample(dataset_dicts, 3):
    im = cv2.imread(d["file_name"])
    # Check if image was loaded successfully
    if im is not None:
        outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format
        v = Visualizer(im[:, :, ::-1],
                       #metadata=balloon_metadata,
                       scale=0.5,
                       instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models
        )
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        cv2_imshow(out.get_image()[:, :, ::-1])
    else:
        print(f"Failed to load image: {d['file_name']}")

"""We can also evaluate its performance using AP metric implemented in COCO API.
This gives an AP of ~70. Not bad!
"""

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
predictor = DefaultPredictor(cfg)
evaluator = COCOEvaluator("/content/Strawberry-Diseases-1/val", output_dir="./output")
val_loader = build_detection_test_loader(cfg, "/content/Strawberry-Diseases-1/val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))
# another equivalent way to evaluate the model is to use `trainer.test`

"""# Other types of builtin models

We showcase simple demos of other types of models below:
"""

# Inference with a keypoint detection model - This is only aplicable for coco dataset , persons
cfg = get_cfg()   # get a fresh new config
cfg.merge_from_file(model_zoo.get_config_file("COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml")
predictor = DefaultPredictor(cfg)
outputs = predictor(im)
v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(out.get_image()[:, :, ::-1])

# Inference with a panoptic segmentation model
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml"))
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml")
predictor = DefaultPredictor(cfg)
panoptic_seg, segments_info = predictor(im)["panoptic_seg"]
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
out = v.draw_panoptic_seg_predictions(panoptic_seg.to("cpu"), segments_info)
cv2_imshow(out.get_image()[:, :, ::-1])

"""# Run panoptic segmentation on a video"""

# This is the video we're going to process
from IPython.display import YouTubeVideo, display
video = YouTubeVideo("ll8TgCZ0plk", width=500)
display(video)

# Install dependencies, download the video, and crop 5 seconds for processing
!pip install youtube-dl
!youtube-dl https://www.youtube.com/watch?v=ll8TgCZ0plk -f 22 -o video.mp4
!ffmpeg -i video.mp4 -t 00:00:06 -c:v copy video-clip.mp4

# Commented out IPython magic to ensure Python compatibility.
# Run frame-by-frame inference demo on this video (takes 3-4 minutes) with the "demo.py" tool we provided in the repo.
!git clone https://github.com/facebookresearch/detectron2
# Note: this is currently BROKEN due to missing codec. See https://github.com/facebookresearch/detectron2/issues/2901 for workaround.
# %run detectron2/demo/demo.py --config-file detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml --video-input video-clip.mp4 --confidence-threshold 0.6 --output video-output.mkv \
  --opts MODEL.WEIGHTS detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_101_3x/139514519/model_final_cafdb1.pkl

# Download the results
from google.colab import files
files.download('video-output.mkv')